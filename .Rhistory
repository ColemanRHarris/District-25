xs1
which(xs1==i)
length(xs1[which(xs1==i)])
nrow(xs1)
length(xs1[which(xs1==i)])/length(xs1)
x <- data.frame(matrix(NA,nrow=11,ncol=4))
names(x) <- c("a_20","b_20","X_20","P(X_20 = x)")
x$a_20 <- c("10","9; 11", "8; 12", "7; 13","6; 14", "5; 15", "4; 16","3; 17","2; 18","1; 19","0; 20")
x$b_20 <- c("10", "11; 9", "12; 8", "13; 7", "14; 6", "15; 5", "16; 4", "17; 3", "18; 2", "19; 1", "20; 0")
x$X_20 <- seq(0,20,2)
i <- 0
while(i < nrow(x)){
x[i,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
}
knitr::kable(x)
i <- 0
while(i < nrow(x)){
x[i,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2
}
length(xs1[which(xs1==i)])/length(xs1)
i <- 0; j <- 1
while(i < nrow(x)){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
xs1
max(xs1)
i <- 12
length(xs1[which(xs1==i)])/length(xs1)
i <- 0; j <- 1
while(i < nrow(x)){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
i <- 0; j <- 1
while(i < 20){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
i <- 0; j <- 1
while(i <= 20){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
sims1 <- function(){
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
#holds imbalance
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
#pi <- 0
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
#return(xs[20]) #2
return(max(xs)) #3
}
loops <- 10^4; xs1 <- rep(NA, loops)
for(i in 1:loops){
xs1[i] <- sims1()
}
quantile(xs1)
max(xs1)
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
xs
max(xs)
x[20]
xs[20]
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
xs
max(xs)
x[20]
xs[20]
hist(xs1)
sims1 <- function(){
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
#holds imbalance
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
#pi <- 0
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
#return(xs[20]) #2
return(max(xs)) #3
}
loops <- 10^4; xs1 <- rep(NA, loops)
for(i in 1:loops){
xs1[i] <- sims1()
}
xs1
max(xs1)
#turning it into a kable
x <- data.frame(matrix(NA,nrow=11,ncol=4))
names(x) <- c("a_20","b_20","X_20","P(X_20 = x)")
x$a_20 <- c("10","9; 11", "8; 12", "7; 13","6; 14", "5; 15", "4; 16","3; 17","2; 18","1; 19","0; 20")
x$b_20 <- c("10", "11; 9", "12; 8", "13; 7", "14; 6", "15; 5", "16; 4", "17; 3", "18; 2", "19; 1", "20; 0")
x$X_20 <- seq(0,20,2)
i <- 0; j <- 1
while(i <= 20){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
sims1 <- function(){
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
#holds imbalance
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
#pi <- 0
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
return(xs[20]) #2
#return(max(xs)) #3
}
loops <- 10^4; xs1 <- rep(NA, loops)
for(i in 1:loops){
xs1[i] <- sims1()
}
#turning it into a kable
x <- data.frame(matrix(NA,nrow=11,ncol=4))
names(x) <- c("a_20","b_20","X_20","P(X_20 = x)")
x$a_20 <- c("10","9; 11", "8; 12", "7; 13","6; 14", "5; 15", "4; 16","3; 17","2; 18","1; 19","0; 20")
x$b_20 <- c("10", "11; 9", "12; 8", "13; 7", "14; 6", "15; 5", "16; 4", "17; 3", "18; 2", "19; 1", "20; 0")
x$X_20 <- seq(0,20,2)
i <- 0; j <- 1
while(i <= 20){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
knitr::kable(x)
#redo above using max(X)
sims1 <- function(){
p1 <- 0.5
alloc <- rep(0,20) #let b be 0s, a is 1s
alloc[1] <- rbinom(size = 1, n=1, prob=p1)
#holds imbalance
xs <- rep(NA,20)
xs[1] <- 1 #either abs(0-1) or abs(1-0) -- always 1
#pi <- 0
pi <- p1
a <- alloc[1] #0 if b, 1 if a
for(i in 2:20){
pi <- (i - a)/(i + 1)
alloc[i] <- rbinom(size=1,n=1,prob=pi)
a <- sum(alloc)
b <- (i - a)
xs[i] <- abs(a - b)
}
#return(xs[20]) #2
return(max(xs)) #3
}
loops <- 10^4; xs1 <- rep(NA, loops)
for(i in 1:loops){
xs1[i] <- sims1()
}
#turning it into a kable
x <- data.frame(matrix(NA,nrow=11,ncol=4))
names(x) <- c("a_20","b_20","X_20","P(X_20 = x)")
x$a_20 <- c("10","9; 11", "8; 12", "7; 13","6; 14", "5; 15", "4; 16","3; 17","2; 18","1; 19","0; 20")
x$b_20 <- c("10", "11; 9", "12; 8", "13; 7", "14; 6", "15; 5", "16; 4", "17; 3", "18; 2", "19; 1", "20; 0")
x$X_20 <- seq(0,20,2)
i <- 0; j <- 1
while(i <= 20){
x[j,]$`P(X_20 = x)` <- length(xs1[which(xs1==i)])/length(xs1)
i <- i + 2; j <- j + 1
}
knitr::kable(x)
library(Hmisc)
latex(x,file="")
t1 <- trialp(pe=.9,pc=.1)
t1
orcon.lik=function(table, lolim=0, hilim=100, main1 =
"Conditional Likelihood For Odds Ratio\n",
main2, OR2, dgt = 3, acc = 1, fignum)
{
###############################################################
## Function: 	orcon.lik
## Author:		Richard Royall & Jeffrey Blume
## Origin:		November 1998
## Revision:	February 2015
##
## Purpose:	Plot conditional likelihood function for odds
##    		ratio in two-binomial model (condition on sum).
##			Revision added profile likelihood, estimated
##			likelihood, exact and pearson p-values, and
##			p-values based on maximum likelihood ratio as
##			described in Choi et. al. 2015.
##
## Input:	x successes in m trials & y successes in n.
##			table = c(a,b,c,d)
##			where x=a, m=a+b and y=c, n=c+d
##
## Notes:	Likelihood function evaluated at 1000*acc points
###############################################################
########################
#### Data/Preliminaries
########################
##	compute successes and trials in each group
x <- table[1,1]
m <- sum(table[1,])
y <- table[2,1]
n <- sum(table[2,])
########################
#### Hypothesis Testing
########################
## Fisher's exact Test
ft <- fisher.test(table)
## Pearson Chi-Square
ct <- chisq.test(table)
## Chi-square with continuity correction
ctc <- chisq.test(table,correct=FALSE)
## Get p-values
pv <- data.frame(Fisher=ft$p.value,Pearson=ct$p.value,PearsonCC=ctc$p.value,row.names="p.value")
########################
#### Likelihoods
########################
## Conditional Likelihood (Non-Central Hypergeometric)
k <- x + y
s <- max(k - n, 0):min(m, k)
lcoeff <- lgamma(x + 1) + lgamma(m - x + 1) +
lgamma(k - x + 1) + lgamma(n - k + x +
1) - lgamma(s + 1) - lgamma(m - s + 1) -
lgamma(k - s + 1) - lgamma(n - k + s +
1)
if(x * y * (m - x) * (n - y) >= 1) {
psi <- (x * (n - y))/(y * (m - x))
std <- sqrt(1/x + 1/y + 1/(m - x) + 1/(
n - y))
ll <- exp(log(psi) - 5 * std)
ul <- exp(log(psi) + 5 * std)
}
if(x * (n - y) == 0) {
ll <- 0
ul <- 2
}
if(y * (m - x) == 0) {
ll <- 0
ul <- 16
}
if(missing(lolim))
lolim <- ll
if(missing(hilim))
hilim <- ul
z <- c(1, if(missing(OR2)) 1 else OR2, seq(
lolim, hilim, len = 1000 * acc))
lik <- t(matrix(z, nrow = length(z), ncol =
length(s)))
lik <- t(lik^(s - x))
lik <- 1/(lik %*% exp(lcoeff))
##   Now lik is the (unscaled) likelihood fn.
if(y * (m - x) == 0) {
lik <- lik * exp(lcoeff[length(s)])
psihat <- NA
}
else {
if(x * y * (m - x) * (n - y) >= 1 && {
max(lik) == lik[length(lik)] ||
max(lik) == lik[3]
}
) {
llloc <- exp(log(psi) - 0.5 *
std)
ulloc <- exp(log(psi) + 0.5 *
std)
zloc <- seq(llloc, ulloc, len
= 500)
likloc <- t(matrix(zloc, nrow
= length(zloc), ncol
= length(s)))
likloc <- t(likloc^(s - x))
likloc <- 1/(likloc %*% exp(
lcoeff))
lik <- lik/max(likloc)
psihat <- zloc[likloc == max(
likloc)]
}
else {
lik <- lik/max(lik)
psihat <- z[lik == max(lik)]
}
}
if(missing(OR2))
LR <- min(1/lik[1], 1000000)
else LR <- min(lik[2]/lik[1], 1000000)
z0 <- z[3:length(z)]
lik0 <- lik[3:length(lik)]
z1 <- z0[lik0 >= 1/8]
i1 <- rep(1/8, length(z1))
z2 <- z0[lik0 >= 1/32]
i2 <- rep(1/32, length(z2))
if(missing(main2)) {
main2 <- paste("Observed proportions:",
x, "/", m, "and", y, "/", n)
sub1 <- " "
}
else sub1 <- paste("Observed proportions:", x,
"/", m, "and", y, "/", n)
## Two-group Binomial Likelihood
## The correct or 'true' likelihood is the produce of two binomials
## reparameterized from ( p1, p2 ) --> ( log(or), log(p2/(1-p2)) )
## This is just
## exp(psi*y1)*exp(lam*(y1+y2))*((1+exp(psi+lam))^(-n1))*((1+exp(lam))^(-n2))
##		where psi = log(OR) and lam = log(p2/(1-p2))
## Function to compute log-likelihood
loglik <- function(or,lam,tabf=table){log(or)*tabf[1,1]+
lam*(sum(tabf[,1]))-sum(tabf[1,])*log(1+exp(log(or)+lam))-
sum(tabf[2,])*log(1+exp(lam))}
## Set range of oddsratio and logOdds grp2 (hidden)
lo.or = 0 ; hi.or = hilim
lo.lam = -15 ; hi.lam = 15
or = seq(lo.or,hi.or,len=(10000*acc+1))
lam = seq(lo.lam,hi.lam,len=(1000*acc+1))
## Find the global MLE for lambda based on group 2 ; reparameterized [pg 374]
lam.max = log(table[2,1]/table[2,2])
or.null = which.min(abs(or - 1))
# instead of which(or==1) b/c 1 might not be in the or vector
## Estimated likelihood (uses lam.max for plug-in of nusiance parameter lambda)
# Note: The estimted likelihood essentially assumes lam.max is 'correct'
#		so the likelihood is too concentrated because estimate is
#		treated as a known constant.
llik.est = loglik(or,lam.max)
lik.est  = exp(llik.est-max(llik.est))    # scale the function between 0 and 1
lre = 1/lik.est[or.null]
# The numerator is max(lik.est)==1 because of the scaling
# this is the LR for the MLE versus 1 (for the or)
pv.e = 1-pchisq((2*log(lre)),df=1)
# -2*log(LR) ~ chisq(df=1) ; forumla from Choi et. al. (2015) [pg 17]
lr.e = data.frame(p.value=pv.e,maxLR=lre,row.names="Est.Like")
## Profile likelihood (uses the MLE lambda for each OR )
# Note: The profile likelihood plugs in the best estimator for lambda
#		conditional on each OR. That is, for each OR, it finds the best
#		estimate of lambda. As a result, the plug-in estimate of lambda
#		changes depending on the OR.
llik.pro = outer(or,lam,"loglik",tabf=table) 	# "order" tries all combinations
llik.pro = apply(llik.pro,1,max)		# maximizes likelihood over lambda for each OR
lik.pro  = exp(llik.pro-max(llik.pro)) 	# scale the function between 0 and 1
lrp = 1/lik.pro[or.null]
# The numerator is max(lik.pro)==1 because of the scaling
# this is the LR for the MLE versus 1 (for the or)
pv.p = 1-pchisq((2*log(lrp)),df=1)
# -2*log(LR) ~ chisq(df=1) ; forumla from Choi et. al. (2015) [pg 17]
lr.p = data.frame(p.value=pv.p,maxLR=lrp,row.names="Prof.Like")
########################
#### Plotting
########################
plot(z0, lik0, xlim = c(lolim, hilim), ylim =
range(lik0, 0, 1), type = "l", main =
paste(if(!missing(fignum)) fignum,
main1, main2), xlab = "Odds Ratio",
ylab = " ", sub = sub1)
lines(z1, i1, type = "l")
lines(z2, i2, type = "l")
lines(or,lik.est,col='forestgreen') 	# estimated likelihood
lines(or,lik.pro,col='royalblue')		# Profile likelihood
abline(v=1,lty=2,lwd=0.5)				# Null line
legend(3*(hi.or-lo.or)/4,0.8,c("Conditional","Estimated","Profile"),
lty=1,col=c("black","forestgreen","royalblue"),bty="n")
whr <- if(psihat == "NA") (4 * lolim + hilim)/5
else if(psihat < (lolim + hilim)/2)
(lolim + 4 * hilim)/5
else (4 * lolim + hilim)/5
if(!missing(fignum))
text(whr, 0.87, paste("L(", OR2,
")/L(1)=", signif(LR, dgt)))
else {
text(whr, 0.95, paste("Max at", signif(
psihat, 3), "\n1/8 LI (", if(
min(z1) == z[3] && z[3] == 0)
"0" else if(min(z1) ==
z[3])
"NA"
else if(min(z1) == "NA")
"NA"
else round(min(z1), 2), ",", if(max(z1) ==
z[length(z)]) "NA" else if(max(
z1) == "NA")
"NA"
else round(max(z1), 2), ")",
"\n1/32 LI (", if(min(z2) == z[
3] && z[3] == 0) "0" else if(
min(z2) == z[3])
"NA"
else if(min(z2) == "NA")
"NA"
else round(min(z2), 2), ",", if(max(z2) ==
z[length(z)]) "NA" else if(max(
z2) == "NA")
"NA"
else round(max(z2), 2), ")", "\nL(",
if(missing(OR2)) signif(psihat,
dgt) else signif(OR2,
dgt), if(LR == 1000000
) ")/L(1)>" else ")/L(1)=",
signif(LR, dgt)))
}
## Show p-values and conditional LR p-value
## as suggested in Choi et. al. (2015)
pv.c = 1-pchisq((2*log(LR)),df=1)
# -2*log(LR) ~ chisq(df=1) ; forumla from Choi et. al. (2015) [pg 17]
lr.c = data.frame(p.value=pv.c,maxLR=LR,row.names="Cond.Like")
out=rbind(data.frame(cbind(t(pv),maxLR=rep(NA,3))),lr.c,lr.e,lr.p)
print(out, digits=5)
}
table1=matrix(c(1,9,5,5),ncol=2,byrow=TRUE)   # Example from Choi et. al. (2015)
table1
plot(table1)
orcon.lik(table1,hilim=2)
table2=matrix(c(11,3,1,9),ncol=2,byrow=TRUE)
orcon.lik(table2,hilim=100)
table3=matrix(c(16,14,12,68),ncol=2,byrow=TRUE)
orcon.lik(table3,hilim=30)
?include_graphics
library(shiny); runApp('Desktop/Campaigns/Wade Munday - TN Senate District 25/github/District-25/PrecinctDatawithShiny.R')
setwd("~/")
setwd("~/Desktop/Campaigns/Wade Munday - TN Senate District 25/github/District-25")
runApp('PrecinctDatawithShiny.R')
runApp('PrecinctDatawithShiny.R')
runApp('PrecinctDatawithShiny.R')
cty_dat <- read_csv("countydata.csv")
View(cty_dat)
seq(0,12,4)
cty_dat[6,1:5]
cty_dat[6,1:5] <- seq(0,12,4)
cty_dat <- read_csv("countydata.csv"); cty_dat[6,1:5] <- c(seq(0,12,4),-1)
cty_dat <- read_csv("countydata.csv"); cty_dat[6,1:4] <- eq(0,12,4)
cty_dat <- read_csv("countydata.csv"); cty_dat[6,1:4] <- seq(0,12,4)
cty_dat <- read_csv("countydata.csv"); cty_dat[6,2:5] <- seq(0,12,4)
cty_dat <- read_csv("countydata.csv")
View(cty_dat)
lm(cty_dat$cheatham ~ cty_dat$year)
l <- lm(cty_dat$cheatham ~ cty_dat$year)
l$residuals
l$fitted.values
attach(cty_dat)
cbind(cheatham,dickson,hickman,humphreys,robertson)
rbind(cheatham,dickson,hickman,humphreys,robertson)
cty_dat <- read_csv("countydata.csv")
cty_dat <- read_csv("countydata.csv",sep=" ")
grepl
grepl(pattern=" ",x = cty_dat)
grep(pattern=" ",x = cty_dat)
read.table("countydata.csv",sep = " ")
read.table("countydata.csv",sep = "\t")
read.table("countydata.csv",sep = "\t",col.names = T)
read.table("countydata.csv",sep = "\t",header = T)
cty_dat <- read.table("countydata.csv",sep = "\t",header = T)
l <- lm(cty_dat$county ~ cty_dat$year)
l <- lm(cty_dat$votes ~ cty_dat$year)
l
library(ggplot2)
ggplot(data=cty_dat) + geom_point(aes(year,votes)) + facet_wrap(county)
ggplot(data=cty_dat) + geom_point(aes(year,votes)) + facet_wrap(~county)
g <- ggplot(data=cty_dat) + geom_point(aes(year,votes,col=county)) + facet_wrap(~county)
g <- ggplot(data=cty_dat) + geom_point(aes(year,votes,color=county)) + facet_wrap(~county)
g
g <- ggplot(data=cty_dat) + geom_point(aes(year,votes,color=county)) + facet_wrap(~county) + scale_x_discrete(c(2002,2006,2010,2014,2018))
g
g <- ggplot(data=cty_dat) + geom_point(aes(year,votes,color=county))  + scale_x_discrete(c(2002,2006,2010,2014,2018)) + facet_wrap(~county)
g
g <- ggplot(data=cty_dat) + geom_point(aes(year,votes,color=county)) + facet_wrap(~county)
?lapply
